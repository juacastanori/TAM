{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juacastanori/TAM/blob/main/Parcial_1/TAM_Dashboard_Parcial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalación de librerías**"
      ],
      "metadata": {
        "id": "Elnq10QfBNM3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rkQn_3iV7Ck-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3462348d-d7b7-4319-ff68-8facd5e3cb59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#instalación de librerías\n",
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Crear carpeta pages para trabajar Multiapp en Streamlit"
      ],
      "metadata": {
        "id": "uFYn5Ura7jxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir pages"
      ],
      "metadata": {
        "id": "j_yjXe027jRG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Página principal**"
      ],
      "metadata": {
        "id": "w7teY1GZ80jN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Dataset_Processing.py\n",
        "\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import requests\n",
        "import subprocess\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pandas.plotting import scatter_matrix\n",
        "import io\n",
        "from PIL import Image\n",
        "\n",
        "st.set_page_config(page_title=\"Preprocesamiento Ames\", page_icon=\"📊\")\n",
        "st.title(\"📊 Preprocesamiento del Dataset Ames Housing\")\n",
        "\n",
        "# === Descargar automáticamente archivos desde Google Drive si no existen ===\n",
        "ARCHIVOS = {\n",
        "    \"ames.csv\": \"1nsYKXBr0JtdWQWzSbtlAk6Qjj-YU_aSl\",\n",
        "    \"cv.png\": \"11RjAsmB3i7a9UskrQuMkBpUW9xpLZ3Eu\"\n",
        "}\n",
        "\n",
        "st.subheader(\"🔄 Verificando archivos necesarios\")\n",
        "try:\n",
        "    subprocess.run([\"pip\", \"install\", \"gdown\"], check=True)\n",
        "    import gdown\n",
        "except Exception as e:\n",
        "    st.error(f\"No se pudo instalar gdown: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "with st.spinner(\"⏳ Descargando Dataset (Ames Housing)...\"):\n",
        "    for nombre, file_id in ARCHIVOS.items():\n",
        "        if not os.path.exists(nombre):\n",
        "            try:\n",
        "                url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "                gdown.download(url, nombre, quiet=False)\n",
        "            except Exception as e:\n",
        "                st.error(f\"❌ No se pudo descargar {nombre}: {e}\")\n",
        "                st.stop()\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "### El Ames Housing Dataset es un conjunto de datos que contiene información detallada sobre las características de viviendas en Ames, Iowa, y sus respectivos precios de venta. Es ampliamente utilizado para prácticas de regresión debido a su riqueza en variables y complejidad moderada.\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "### Características del conjunto de datos\n",
        "\"\"\")\n",
        "st.markdown(\"\"\"\n",
        "\n",
        "• Número de observaciones: 2,930 propiedades.\n",
        "\n",
        "• Número de variables: 80 características que describen cada propiedad.\n",
        "\"\"\")\n",
        "st.markdown(\"\"\"\n",
        "### Tipos de variables:\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "• Numéricas continuas: como LotArea, GrLivArea, SalePrice.\n",
        "\n",
        "• Numéricas discretas: como BedroomAbvGr, TotRmsAbvGrd.\n",
        "\n",
        "• Categóricas nominales: como Neighborhood, HouseStyle.\n",
        "\n",
        "• Categóricas ordinales: como ExterQual, BsmtQual.\n",
        "\n",
        "• Variable de salida: El target del dataset es la variable \"SalePrice\" que representa el precio de las casas\n",
        "\"\"\")\n",
        "\n",
        "# === Cargar y validar el archivo ===\n",
        "try:\n",
        "    df = pd.read_csv(\"ames.csv\")\n",
        "    if df.empty or df.shape[1] < 2:\n",
        "        st.error(\"El archivo CSV está vacío o corrupto.\")\n",
        "        st.stop()\n",
        "    if \"SalePrice\" not in df.columns:\n",
        "        st.error(\"La columna 'SalePrice' no está en los datos.\")\n",
        "        st.stop()\n",
        "    st.markdown(\"\"\"\n",
        "    ### Vista previa del Dataset\n",
        "    \"\"\")\n",
        "    st.dataframe(df.head())\n",
        "\n",
        "    # Mostrar df.info() de forma bonita\n",
        "    buffer = io.StringIO()\n",
        "    df.info(buf=buffer)\n",
        "    info_str = buffer.getvalue()\n",
        "    st.code(info_str, language='text')\n",
        "\n",
        "    # Escribir texto explicativo\n",
        "    st.markdown(\"\"\"\n",
        "    Se presentan atributos tipo int, float y texto, algunos de ellos con datos perdidos. Para este caso, se eliminarán columnas:\n",
        "\n",
        "    **Order**: Solo un índice de entrada\n",
        "    **PID**: ID único de la propiedad\n",
        "\n",
        "    Estas columnas no aportan información útil para predecir `SalePrice`.\n",
        "\n",
        "    Las siguientes columnas tienen porcentajes de valores faltantes muy grandes, por lo tanto se van a eliminar:\n",
        "\n",
        "    - **Pool QC** ~99.6% nulos\n",
        "    - **Misc Feature** ~96.4% nulos\n",
        "    - **Alley** ~93% nulos\n",
        "    - **Fence** ~80.5% nulos\n",
        "    - **Fireplace Qu** ~49% nulos\n",
        "\n",
        "    Estas columnas se van a eliminar.\n",
        "    \"\"\")\n",
        "\n",
        "    # === Gráfico de SalePrice vs índice ===\n",
        "    fig_price = plt.figure(figsize=(10, 4))\n",
        "    plt.plot(df.index, df['SalePrice'])\n",
        "    plt.title(\"SalePrice en función del índice de la casa\")\n",
        "    plt.xlabel(\"Índice\")\n",
        "    plt.ylabel(\"SalePrice\")\n",
        "    st.pyplot(fig_price)\n",
        "\n",
        "    # === Preprocesamiento ===\n",
        "    df.drop(columns=[\"Order\", \"PID\", \"Pool QC\", \"Misc Feature\", \"Alley\", \"Fence\", \"Fireplace Qu\"], inplace=True)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    Se va a partir la base de datos para 70% entrenamiento y 30% validación.\n",
        "    Se usará `OrdinalEncoder` para codificar las variables tipo texto.\n",
        "    Para los valores faltantes en el dataset, se imputarán como la **moda** de los datos si la variable es categórica, y como la **mediana** si es numérica.\n",
        "    \"\"\")\n",
        "\n",
        "    # Separar variable objetivo\n",
        "    col_sal = \"SalePrice\"\n",
        "    Xtrain, Xtest = train_test_split(df, test_size=0.3, random_state=42)\n",
        "    ytrain = Xtrain[col_sal].copy()\n",
        "    ytest = Xtest[col_sal].copy()\n",
        "    Xtrain.drop(columns=[col_sal], inplace=True)\n",
        "    Xtest.drop(columns=[col_sal], inplace=True)\n",
        "\n",
        "    # Identificar columnas categóricas\n",
        "    cat_cols = df.select_dtypes(include='object').columns.tolist()\n",
        "    cat_items = []\n",
        "    for col in cat_cols:\n",
        "        cat_items.append(list(df[col].value_counts().index))\n",
        "    cat_usr = dict(zip(cat_cols, cat_items))\n",
        "\n",
        "    ordinal_encoder = OrdinalEncoder(categories=[cat_usr[col] for col in cat_cols])\n",
        "    cat_cols = df.select_dtypes(include='object').columns\n",
        "    cat_usr = {col: list(df[col].dropna().unique()) for col in cat_cols}\n",
        "\n",
        "    # Clase de preprocesamiento\n",
        "    class AmesPreprocessor(BaseEstimator, TransformerMixin):\n",
        "        def __init__(self, cat_usr):\n",
        "            self.cat_usr = cat_usr\n",
        "\n",
        "        def fit(self, X, *_):\n",
        "            Xi = X.copy()\n",
        "            self.cat_cols = list(self.cat_usr.keys())\n",
        "            self.num_cols = [col for col in Xi.columns if col not in self.cat_cols]\n",
        "            self.imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "            self.imputer_num = SimpleImputer(strategy=\"median\")\n",
        "            Xi[self.cat_cols] = self.imputer_cat.fit_transform(Xi[self.cat_cols])\n",
        "            Xi[self.num_cols] = self.imputer_num.fit_transform(Xi[self.num_cols])\n",
        "            self.encoder = OrdinalEncoder(categories=[self.cat_usr[col] for col in self.cat_cols])\n",
        "            Xi[self.cat_cols] = self.encoder.fit_transform(Xi[self.cat_cols])\n",
        "            return self\n",
        "\n",
        "        def transform(self, X, *_):\n",
        "            Xi = X.copy()\n",
        "            Xi[self.cat_cols] = self.imputer_cat.transform(Xi[self.cat_cols])\n",
        "            Xi[self.num_cols] = self.imputer_num.transform(Xi[self.num_cols])\n",
        "            Xi[self.cat_cols] = self.encoder.transform(Xi[self.cat_cols])\n",
        "            return Xi\n",
        "\n",
        "    preprocessor = AmesPreprocessor(cat_usr=cat_usr)\n",
        "    Xtrain_pre = preprocessor.fit_transform(Xtrain)\n",
        "    Xtest_pre = preprocessor.transform(Xtest)\n",
        "\n",
        "    # Matriz de correlación\n",
        "    st.markdown(\"\"\"\n",
        "\n",
        "    ---\n",
        "\n",
        "    ### Se grafica la matriz de correlaciones:\n",
        "    \"\"\")\n",
        "    Xtrain_pre2 = pd.DataFrame(Xtrain_pre, columns=Xtrain.columns)\n",
        "    Xtrain_pre2['output'] = ytrain\n",
        "    corr_matrix2 = Xtrain_pre2.corr()\n",
        "    fig_corr, ax_corr = plt.subplots(figsize=(20, 18))\n",
        "    sns.heatmap(corr_matrix2, cmap=\"coolwarm\", annot=False, ax=ax_corr)\n",
        "    ax_corr.set_title(\"Matriz de correlación completa con 'output'\")\n",
        "    st.pyplot(fig_corr)\n",
        "\n",
        "    # Variables más correlacionadas con output\n",
        "    st.markdown(\"\"\"\n",
        "    ### Se presentan las variables que más tienen relación con la salida (output):\n",
        "    \"\"\")\n",
        "    top_corr_vars = abs(corr_matrix2[\"output\"]).sort_values(ascending=False)\n",
        "    st.dataframe(top_corr_vars)\n",
        "\n",
        "    # Visualización de atributos seleccionados\n",
        "    cols = ['OverallQual', 'GrLivArea', 'GarageArea']\n",
        "    Xm =pd.DataFrame(Xtrain_pre[['Overall Qual','Gr Liv Area','Garage Area']],columns=['Overall Qual','Gr Liv Area','Garage Area'])#definir pandas con atributos seleccionados\n",
        "    Xm['Output'] = ytrain #agregar salida\n",
        "\n",
        "    # Escalado y visualización\n",
        "    scaler = MinMaxScaler()\n",
        "    Xm_pre_sca = pd.DataFrame(scaler.fit_transform(Xm), columns=Xm.columns)\n",
        "\n",
        "    st.markdown(\"\"\"\n",
        "    ### Diagramas de bigotes y dispersion para algunas variables\n",
        "    \"\"\")\n",
        "\n",
        "    fig_box, ax_box = plt.subplots()\n",
        "    Xm_pre_sca.boxplot(ax=ax_box)\n",
        "    st.pyplot(fig_box)\n",
        "\n",
        "    #fig_scatter = plt.figure(figsize=(12, 8))\n",
        "    #scatter_matrix(Xm_pre_sca, figsize=(12, 8))\n",
        "    #plt.tight_layout()\n",
        "    #st.pyplot(fig_scatter)\n",
        "\n",
        "\n",
        "    fig_scatter = scatter_matrix(Xm_pre_sca, figsize=(12, 8), diagonal='hist')\n",
        "\n",
        "    # Forzar layout y visualización\n",
        "    plt.tight_layout()\n",
        "    st.pyplot(plt.gcf())  # plt.gcf() agarra la figura generada automáticamente\n",
        "\n",
        "    # Variables más correlacionadas con output\n",
        "    st.markdown(\"\"\"\n",
        "    ### Se hará validación cruzada para entrenar:\n",
        "    \"\"\")\n",
        "\n",
        "    # === Imagen de superficie de búsqueda Optuna ===\n",
        "    st.subheader(\"🌐 Validación cruzada \")\n",
        "    try:\n",
        "        image = Image.open(\"cv.png\")\n",
        "        st.image(image, caption=\"CV=5 Folds\", use_container_width=True)\n",
        "    except Exception as e:\n",
        "        st.warning(f\"No se pudo cargar la imagen: {e}\")\n",
        "\n",
        "except Exception as e:\n",
        "    st.error(f\"❌ Error al leer el archivo CSV: {e}\")\n",
        "    st.stop()\n"
      ],
      "metadata": {
        "id": "lkE-F8Jy87pW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd8a2795-ca54-4055-8b98-8ad72e5844ff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing Dataset_Processing.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Páginas**"
      ],
      "metadata": {
        "id": "7oRBr8cBtwrl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 📈_Model_1.py\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from PIL import Image\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "st.set_page_config(page_title=\"Modelo 1\", page_icon=\"📊\")\n",
        "st.title(\"📊 Evaluación del Modelo KernelRidge con Optimización Bayesiana\")\n",
        "\n",
        "# === Descargar automáticamente archivos desde Google Drive si no existen ===\n",
        "ARCHIVOS = {\n",
        "    \"ytest.csv\": \"13i0LmC1XgPAXgAWtuqaSWZE-VVy-nzWC\",\n",
        "    \"ypred_test.csv\": \"1WQUtaljvMU0rbGQOLM8DcfdZ_gih9Ihg\",\n",
        "    \"bayes_opt_mae.png\": \"1Th_afKZyRHj4YDGyNpVcmwYLd8RQgogS\",\n",
        "    \"pred_vs_real.png\": \"1lMGQH2u-EJRh3BBklceR-VFRNZI8Qasz\",\n",
        "    \"kern_h.png\": \"19CCcwa-IyDr_mX94509S9JG9ispxrjnE\"\n",
        "}\n",
        "\n",
        "st.subheader(\"🔄 Verificando archivos necesarios\")\n",
        "try:\n",
        "    subprocess.run([\"pip\", \"install\", \"gdown\"], check=True)\n",
        "    import gdown\n",
        "except Exception as e:\n",
        "    st.error(f\"No se pudo instalar gdown: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "with st.spinner(\"⏳ Descargando modelo...\"):\n",
        "    for nombre, file_id in ARCHIVOS.items():\n",
        "        if not os.path.exists(nombre):\n",
        "            try:\n",
        "                url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "                gdown.download(url, nombre, quiet=False)\n",
        "            except Exception as e:\n",
        "                st.error(f\"❌ No se pudo descargar {nombre}: {e}\")\n",
        "                st.stop()\n",
        "\n",
        "# === Cargar vectores guardados ===\n",
        "st.subheader(\"📥 Cargando datos numpy\")\n",
        "try:\n",
        "    ytest = pd.read_csv(\"ytest.csv\", header=None).squeeze().values\n",
        "    ypred_test = pd.read_csv(\"ypred_test.csv\", header=None).squeeze().values\n",
        "    st.success(\"Datos cargados exitosamente.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"❌ Error al cargar archivos: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "# === Mostrar explicación y fórmulas de Kernel Ridge Regression ===\n",
        "\n",
        "st.markdown(\"### 🔷 Kernel Ridge Regression (KRR)\")\n",
        "st.markdown(\"El modelo busca minimizar la siguiente **función de costo**:\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "\\min_{f \\in \\mathcal{H}} \\sum_{i=1}^n \\left( y_i - f(x_i) \\right)^2 + \\alpha \\|f\\|_{\\mathcal{H}}^2\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"Donde:\")\n",
        "st.markdown(\"- $\\\\mathcal{H}$: espacio de Hilbert reproducible (RKHS).\")\n",
        "st.markdown(\"- $\\\\alpha > 0$: hiperparámetro de regularización (**mayor** $\\\\alpha$ → **mayor suavidad**).\")\n",
        "st.markdown(\"- $f(x) = \\\\sum_{i=1}^n \\\\beta_i \\\\, K(x, x_i)$, por el teorema representador de representer.\")\n",
        "\n",
        "st.markdown(\"### ✅ Solución en forma dual (matricial)\")\n",
        "st.markdown(\"La solución puede escribirse como:\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "\\boldsymbol{\\beta} = \\left( K + \\alpha I \\right)^{-1} \\mathbf{y}\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"Donde:\")\n",
        "st.markdown(\"- $K$: matriz de kernel con entradas $K_{ij} = K(x_i, x_j)$\")\n",
        "st.markdown(\"- $I$: matriz identidad\")\n",
        "st.markdown(\"- $\\\\alpha$: hiperparámetro de regularización\")\n",
        "\n",
        "st.markdown(\"Entonces, para una nueva muestra $x$, la predicción es:\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "\\hat{y}(x) = \\sum_{i=1}^n \\beta_i \\cdot K(x, x_i)\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"### 🔶 Usando el kernel RBF (Radial Basis Function)\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "K(x_i, x_j) = \\exp \\left( -\\gamma \\|x_i - x_j\\|^2 \\right)\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"Donde:\")\n",
        "st.markdown(\"- $\\\\gamma > 0$: controla la **anchura del kernel**, y por tanto la **complejidad del modelo**.\")\n",
        "st.markdown(\"  - Bajo $\\\\gamma$ → función más suave\")\n",
        "st.markdown(\"  - Alto $\\\\gamma$ → modelo más complejo, riesgo de sobreajuste\")\n",
        "\n",
        "\n",
        "# === Gráfico Real vs Predicho (desde imagen) ===\n",
        "st.subheader(\"📈 Gráfico Hiperparametros\")\n",
        "try:\n",
        "    image1 = Image.open(\"pred_vs_real.png\")\n",
        "    st.image(image1, caption=\"Gráfico de Hiperparámetros\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen del gráfico: {e}\")\n",
        "\n",
        "# === Imagen de superficie de búsqueda Optuna ===\n",
        "st.subheader(\"🌐 Superficie de búsqueda - Optimización Bayesiana (MAE)\")\n",
        "try:\n",
        "    image2 = Image.open(\"bayes_opt_mae.png\")\n",
        "    st.image(image2, caption=\"Bayesian Optimization (MAE) - alpha vs gamma\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "# === Imagen de mejores parametros ===\n",
        "st.subheader(\"🌐 Mejores parámetros encontrados\")\n",
        "try:\n",
        "    image2 = Image.open(\"kern_h.png\")\n",
        "    st.image(image2, caption=\"Parámetros KernelRidge\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "# === Gráfico ===\n",
        "st.subheader(\"📈 Gráfico Real vs Predicho\")\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(ytest, ypred_test, alpha=0.6)\n",
        "ax.plot([ytest.min(), ytest.max()], [ytest.min(), ytest.max()], 'r--')\n",
        "ax.set_xlabel(\"Valor real\")\n",
        "ax.set_ylabel(\"Valor predicho\")\n",
        "ax.set_title(\"Comparación: Real vs Predicho\")\n",
        "st.pyplot(fig)\n",
        "\n",
        "# === Cálculo de métricas ===\n",
        "st.subheader(\"📊 Métricas de desempeño\")\n",
        "st.write(f\"**MAE:**  {mean_absolute_error(ytest, ypred_test):.2f}\")\n",
        "st.write(f\"**MSE:**  {mean_squared_error(ytest, ypred_test):.2f}\")\n",
        "st.write(f\"**R²:**   {r2_score(ytest, ypred_test):.4f}\")\n",
        "st.write(f\"**MAPE:** {mean_absolute_percentage_error(ytest, ypred_test):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H46wGDpYuFGM",
        "outputId": "7a370f16-a766-4430-f962-5793ecc1fef9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 📈_Model_1.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 📈_Model_1.py pages/"
      ],
      "metadata": {
        "id": "lGfGS2FquIfV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 📈_Model_2.py\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from PIL import Image\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "st.set_page_config(page_title=\"Modelo 2\", page_icon=\"📊\")\n",
        "st.title(\"📊 Evaluación del Modelo SVR con Optimización Bayesiana\")\n",
        "\n",
        "# === Descargar automáticamente archivos desde Google Drive si no existen ===\n",
        "ARCHIVOS = {\n",
        "    \"ytest2.csv\": \"1WPMhossic_eNTR0GawxkcuXya8CvcNej\",\n",
        "    \"ypred_test2.csv\": \"13R1PnV1aSv0OVzESV2rWiXiBb-Jhfc0_\",\n",
        "    \"bayes_opt_mae2.png\": \"1D5KvPMDTQaDHIEIBPg9KtuZhksukzB3r\",\n",
        "    \"bayes_opt_mae22.png\": \"1dHODFguL40l1CaRaqJqi-igJwCJxZk8D\",\n",
        "    \"bayes_opt_mae23.png\": \"1mdbZuCz4U9XNjrU2GM9SPgHR4N25z5qV\",\n",
        "    \"hip1.png\": \"1g_ROu3IxM3po8knSXwz9UcK8F_Pd24ZA\",\n",
        "    \"hip2.png\": \"1H-HhUrMNt9CnsQpZnqzaBYXk_QICQUs7\",\n",
        "    \"hip3.png\": \"1jBFfgigoQ9Ut3PlaGnEI37UPovHsHYKj\",\n",
        "    \"svr_h.png\": \"1Ejfxxg60OGZA9Ldq-8JfWki5fTUdM2tj\"\n",
        "}\n",
        "\n",
        "st.subheader(\"🔄 Verificando archivos necesarios\")\n",
        "try:\n",
        "    subprocess.run([\"pip\", \"install\", \"gdown\"], check=True)\n",
        "    import gdown\n",
        "except Exception as e:\n",
        "    st.error(f\"No se pudo instalar gdown: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "with st.spinner(\"⏳ Descargando modelo...\"):\n",
        "    for nombre, file_id in ARCHIVOS.items():\n",
        "        if not os.path.exists(nombre):\n",
        "            try:\n",
        "                url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "                gdown.download(url, nombre, quiet=False)\n",
        "            except Exception as e:\n",
        "                st.error(f\"❌ No se pudo descargar {nombre}: {e}\")\n",
        "                st.stop()\n",
        "\n",
        "# === Cargar vectores guardados ===\n",
        "st.subheader(\"📥 Cargando datos numpy\")\n",
        "try:\n",
        "    ytest2 = pd.read_csv(\"ytest2.csv\", header=None).squeeze().values\n",
        "    ypred_test2 = pd.read_csv(\"ypred_test2.csv\", header=None).squeeze().values\n",
        "    st.success(\"Datos cargados exitosamente.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"❌ Error al cargar archivos: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "st.markdown(\"### 🔷 Support Vector Regression (SVR)\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "El modelo **SVR** busca encontrar una función que se acerque lo más posible a los datos sin desviarse más de un margen $\\\\varepsilon$, mientras mantiene la complejidad del modelo bajo control.\n",
        "\n",
        "Se formula como un problema de optimización:\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "\\min_{f \\in \\mathcal{H}} \\frac{1}{2} \\|f\\|^2 + C \\sum_{i=1}^n (\\xi_i + \\xi_i^*)\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"Sujeto a las siguientes restricciones:\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "\\begin{aligned}\n",
        "& y_i - f(x_i) \\leq \\varepsilon + \\xi_i \\\\\n",
        "& f(x_i) - y_i \\leq \\varepsilon + \\xi_i^* \\\\\n",
        "& \\xi_i, \\xi_i^* \\geq 0 \\quad \\text{para todo } i\n",
        "\\end{aligned}\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"Donde:\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "- $C$: controla la **penalización** por errores mayores a $\\\\varepsilon$.\n",
        "    - Alto $C$ → menos tolerancia a errores → posible **sobreajuste**\n",
        "    - Bajo $C$ → más margen de error → posible **subajuste**\n",
        "- $\\\\varepsilon$: ancho del **tubo de tolerancia** dentro del cual no se penalizan errores.\n",
        "    - Mayor $\\\\varepsilon$ → modelo más **tolerante**\n",
        "    - Menor $\\\\varepsilon$ → modelo más **preciso**, pero menos robusto\n",
        "- $\\\\xi_i, \\\\xi_i^*$: variables de **holgura** que permiten errores fuera del margen $\\\\varepsilon$\n",
        "- $\\\\|f\\|^2$: norma cuadrada en el espacio de funciones (minimiza la complejidad del modelo)\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"### 🔶 Usando el Kernel RBF\")\n",
        "\n",
        "st.markdown(\"Para datos no lineales, SVR se extiende mediante un **kernel**, típicamente el **RBF (Radial Basis Function)**:\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "K(x_i, x_j) = \\exp \\left( -\\gamma \\|x_i - x_j\\|^2 \\right)\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"Donde:\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "- $\\\\gamma > 0$: controla la **anchura del kernel** y por tanto la **complejidad del modelo**\n",
        "    - Bajo $\\\\gamma$ → función más suave\n",
        "    - Alto $\\\\gamma$ → modelo más complejo, más riesgo de sobreajuste\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"### 🧠 Predicción del modelo:\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "f(x) = \\sum_{i=1}^n (\\alpha_i - \\alpha_i^*) \\cdot K(x, x_i) + b\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"Donde $\\\\alpha_i$ y $\\\\alpha_i^*$ son los multiplicadores de Lagrange obtenidos al resolver el problema dual.\")\n",
        "\n",
        "\n",
        "\n",
        "# === Gráfico Real vs Predicho (desde imagen) ===\n",
        "st.subheader(\"📈 Gráfico Hiperparametros\")\n",
        "try:\n",
        "    image1 = Image.open(\"hip1.png\")\n",
        "    st.image(image1, caption=\"C vs Gamma\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen del gráfico: {e}\")\n",
        "\n",
        "try:\n",
        "    image1 = Image.open(\"hip2.png\")\n",
        "    st.image(image1, caption=\"C vs Epsilon\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen del gráfico: {e}\")\n",
        "\n",
        "try:\n",
        "    image1 = Image.open(\"hip3.png\")\n",
        "    st.image(image1, caption=\"Gamma vs Epsilon\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen del gráfico: {e}\")\n",
        "\n",
        "# === Imagen de superficie de búsqueda Optuna ===\n",
        "st.subheader(\"🌐 Superficie de búsqueda - Optimización Bayesiana (MAE)\")\n",
        "try:\n",
        "    image2 = Image.open(\"bayes_opt_mae2.png\")\n",
        "    st.image(image2, caption=\"Bayesian Optimization (MAE) - C vs gamma\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "try:\n",
        "    image2 = Image.open(\"bayes_opt_mae22.png\")\n",
        "    st.image(image2, caption=\"Bayesian Optimization (MAE) - C vs epsilon\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "try:\n",
        "    image2 = Image.open(\"bayes_opt_mae23.png\")\n",
        "    st.image(image2, caption=\"Bayesian Optimization (MAE) - gamma vs epsilon\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "# === Imagen de mejores parametros ===\n",
        "st.subheader(\"🌐 Mejores parámetros encontrados\")\n",
        "try:\n",
        "    image2 = Image.open(\"svr_h.png\")\n",
        "    st.image(image2, caption=\"Parámetros SVR\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "# === Gráfico ===\n",
        "st.subheader(\"📈 Gráfico Real vs Predicho\")\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(ytest2, ypred_test2, alpha=0.6)\n",
        "ax.plot([ytest2.min(), ytest2.max()], [ytest2.min(), ytest2.max()], 'r--')\n",
        "ax.set_xlabel(\"Valor real\")\n",
        "ax.set_ylabel(\"Valor predicho\")\n",
        "ax.set_title(\"Comparación: Real vs Predicho\")\n",
        "st.pyplot(fig)\n",
        "\n",
        "# === Cálculo de métricas ===\n",
        "st.subheader(\"📊 Métricas de desempeño\")\n",
        "st.write(f\"**MAE:**  {mean_absolute_error(ytest2, ypred_test2):.2f}\")\n",
        "st.write(f\"**MSE:**  {mean_squared_error(ytest2, ypred_test2):.2f}\")\n",
        "st.write(f\"**R²:**   {r2_score(ytest2, ypred_test2):.4f}\")\n",
        "st.write(f\"**MAPE:** {mean_absolute_percentage_error(ytest2, ypred_test2):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjE9YHXaN2Xq",
        "outputId": "38183044-223c-4792-d525-5ddadd8c2055"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 📈_Model_2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 📈_Model_2.py pages/"
      ],
      "metadata": {
        "id": "Qtz7O8p5N6ci"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 📈_Model_3.py\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "from PIL import Image\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "st.set_page_config(page_title=\"Modelo 3\", page_icon=\"📊\")\n",
        "st.title(\"📊 Evaluación del Modelo SVR con Optimización Bayesiana + GridSearch\")\n",
        "\n",
        "# === Descargar automáticamente archivos desde Google Drive si no existen ===\n",
        "ARCHIVOS = {\n",
        "    \"ytest3.csv\": \"1jaIWPi7hLFYN4vVOPRiYG-0wUxI7NEAA\",\n",
        "    \"ypred_test3.csv\": \"1vBZkfxQKSoVR7g-BsQFO4tDiCsJGIbLm\",\n",
        "    \"bayes_opt_maep1.png\": \"1Of5VQUfrbhn6du_fUrOaab4Yk521-4sw\",\n",
        "    \"bayes_opt_maep2.png\": \"1i15iheqwk9QdKrsdSxjp6uYiDg1rtdFg\",\n",
        "    \"bayes_opt_maep3.png\": \"1-2oB-mSBBGxheJ_igtjv33OvHg406C9d\",\n",
        "    \"hip1p.png\": \"1AQ2GonK1165vEaVaQho4RgL5sNzrogpD\",\n",
        "    \"hip2p.png\": \"1O9PFRF30xcl_DkeWd4YWHYovSB3xL8aq\",\n",
        "    \"hip3p.png\": \"1UZGFU5Kthrv5DgkTeJE3OWeVA1WfgH6W\"\n",
        "}\n",
        "\n",
        "st.subheader(\"🔄 Verificando archivos necesarios\")\n",
        "try:\n",
        "    subprocess.run([\"pip\", \"install\", \"gdown\"], check=True)\n",
        "    import gdown\n",
        "except Exception as e:\n",
        "    st.error(f\"No se pudo instalar gdown: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "\n",
        "\n",
        "with st.spinner(\"⏳ Descargando modelo...\"):\n",
        "    for nombre, file_id in ARCHIVOS.items():\n",
        "        if not os.path.exists(nombre):\n",
        "            try:\n",
        "                url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "                gdown.download(url, nombre, quiet=False)\n",
        "            except Exception as e:\n",
        "                st.error(f\"❌ No se pudo descargar {nombre}: {e}\")\n",
        "                st.stop()\n",
        "\n",
        "# === Cargar vectores guardados ===\n",
        "st.subheader(\"📥 Cargando datos numpy\")\n",
        "try:\n",
        "    ytest3 = pd.read_csv(\"ytest3.csv\", header=None).squeeze().values\n",
        "    ypred_test3 = pd.read_csv(\"ypred_test3.csv\", header=None).squeeze().values\n",
        "    st.success(\"Datos cargados exitosamente.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"❌ Error al cargar archivos: {e}\")\n",
        "    st.stop()\n",
        "\n",
        "st.markdown(\"### 🔷 Support Vector Regression (SVR)\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "Problema de optimización:\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "\\min_{f \\in \\mathcal{H}} \\frac{1}{2} \\|f\\|^2 + C \\sum_{i=1}^n (\\xi_i + \\xi_i^*)\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"**kernel** **RBF (Radial Basis Function)**:\")\n",
        "\n",
        "st.latex(r\"\"\"\n",
        "K(x_i, x_j) = \\exp \\left( -\\gamma \\|x_i - x_j\\|^2 \\right)\n",
        "\"\"\")\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "Se implementa un flujo completo de optimización y evaluación para un modelo Support Vector Regressor (SVR) con kernel RBF, usando Optuna para optimización bayesiana y GridSearchCV para refinamiento final\n",
        "\n",
        "Hiperparametros\n",
        "\n",
        "- C: control de penalización\n",
        "\n",
        "- epsilon: margen insensible\n",
        "\n",
        "- gamma: control del alcance del kernel RBF\n",
        "\n",
        "Usa validación cruzada de 5 folds para estimar el error (MAE) y se extrae los 2 mejores resultados de Optuna para construir la grilla fina.\n",
        "\n",
        "Se construyen grillas pequeñas alrededor de los mejores valores (±5% en C y gamma, ±0.015 en epsilon).\n",
        "\n",
        "Se realiza una búsqueda en esa grilla para afinar los hiperparámetros.\n",
        "\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "# === Gráfico Real vs Predicho (desde imagen) ===\n",
        "st.subheader(\"📈 Gráfico Hiperparametros\")\n",
        "try:\n",
        "    image1 = Image.open(\"hip1p.png\")\n",
        "    st.image(image1, caption=\"C vs Gamma\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen del gráfico: {e}\")\n",
        "\n",
        "try:\n",
        "    image1 = Image.open(\"hip2p.png\")\n",
        "    st.image(image1, caption=\"C vs Epsilon\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen del gráfico: {e}\")\n",
        "\n",
        "try:\n",
        "    image1 = Image.open(\"hip3p.png\")\n",
        "    st.image(image1, caption=\"Gamma vs Epsilon\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen del gráfico: {e}\")\n",
        "\n",
        "# === Imagen de superficie de búsqueda Optuna ===\n",
        "st.subheader(\"🌐 Superficie de búsqueda - Optimización Bayesiana (MAE)\")\n",
        "try:\n",
        "    image2 = Image.open(\"bayes_opt_maep1.png\")\n",
        "    st.image(image2, caption=\"Bayesian Optimization (MAE) - C vs gamma\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "try:\n",
        "    image2 = Image.open(\"bayes_opt_maep2.png\")\n",
        "    st.image(image2, caption=\"Bayesian Optimization (MAE) - epsilon vs C\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "try:\n",
        "    image2 = Image.open(\"bayes_opt_maep3.png\")\n",
        "    st.image(image2, caption=\"Bayesian Optimization (MAE) - epsilon vs gamma\", use_container_width=True)\n",
        "except Exception as e:\n",
        "    st.warning(f\"No se pudo cargar la imagen de la búsqueda bayesiana: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# === Gráfico ===\n",
        "st.subheader(\"📈 Gráfico Real vs Predicho\")\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(ytest3, ypred_test3, alpha=0.6)\n",
        "ax.plot([ytest3.min(), ytest3.max()], [ytest3.min(), ytest3.max()], 'r--')\n",
        "ax.set_xlabel(\"Valor real\")\n",
        "ax.set_ylabel(\"Valor predicho\")\n",
        "ax.set_title(\"Comparación: Real vs Predicho\")\n",
        "st.pyplot(fig)\n",
        "\n",
        "# === Cálculo de métricas ===\n",
        "st.subheader(\"📊 Métricas de desempeño\")\n",
        "st.write(f\"**MAE:**  {mean_absolute_error(ytest3, ypred_test3):.2f}\")\n",
        "st.write(f\"**MSE:**  {mean_squared_error(ytest3, ypred_test3):.2f}\")\n",
        "st.write(f\"**R²:**   {r2_score(ytest3, ypred_test3):.4f}\")\n",
        "st.write(f\"**MAPE:** {mean_absolute_percentage_error(ytest3, ypred_test3):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or92-X1afPK_",
        "outputId": "82846d08-3ea1-4e3f-e655-5ec412c43645"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 📈_Model_3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv 📈_Model_3.py pages/"
      ],
      "metadata": {
        "id": "LE_uukbkfWFP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inicialización del Dashboard a partir de túnel local**\n",
        "\n",
        "1. **Reemplazar nombre de archivo**: Reemplaza el nombre del archivo como se indica en el comentario de la linea 6 de la celda de codigo\n",
        "\n",
        "2. **Accede al enlace provisional**: Una vez que la aplicación esté corriendo, LocalTunnel generará un enlace temporal. Haz clic o copia ese enlace para acceder a tu aplicación en el navegador (cada vez que corras la celda, el link podrá ser diferente).\n",
        "\n",
        "**Nota:**\n",
        "Para finalizar la ejecución del Dashboard ejecuta la ultima celda de codigo y sigue las instrucciones."
      ],
      "metadata": {
        "id": "QOJ7v8TmAJ82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "!chmod +x cloudflared-linux-amd64\n",
        "!mv cloudflared-linux-amd64 /usr/local/bin/cloudflared\n",
        "\n",
        "#Ejecutar Streamlit\n",
        "!streamlit run Dataset_Processing.py &>/content/logs.txt & #Cambiar 0_👋_Hello.py por el nombre de tu archivo principal\n",
        "\n",
        "#Exponer el puerto 8501 con Cloudflare Tunnel\n",
        "!cloudflared tunnel --url http://localhost:8501 > /content/cloudflared.log 2>&1 &\n",
        "\n",
        "#Leer la URL pública generada por Cloudflare\n",
        "import time\n",
        "time.sleep(5)  # Esperar que se genere la URL\n",
        "\n",
        "import re\n",
        "found_context = False  # Indicador para saber si estamos en la sección correcta\n",
        "\n",
        "with open('/content/cloudflared.log') as f:\n",
        "    for line in f:\n",
        "        #Detecta el inicio del contexto que nos interesa\n",
        "        if \"Your quick Tunnel has been created\" in line:\n",
        "            found_context = True\n",
        "\n",
        "        #Busca una URL si ya se encontró el contexto relevante\n",
        "        if found_context:\n",
        "            match = re.search(r'https?://\\S+', line)\n",
        "            if match:\n",
        "                url = match.group(0)  #Extrae la URL encontrada\n",
        "                print(f'Tu aplicación está disponible en: {url}')\n",
        "                break  #Termina el bucle después de encontrar la URL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOM4aEY4P62M",
        "outputId": "ca55e051-03ae-4bf7-b4cf-9f071da4770c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-23 20:05:56--  https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/cloudflare/cloudflared/releases/download/2025.5.0/cloudflared-linux-amd64 [following]\n",
            "--2025-05-23 20:05:57--  https://github.com/cloudflare/cloudflared/releases/download/2025.5.0/cloudflared-linux-amd64\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/797840ed-70cb-47b8-a6fe-ecb4b3385c94?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250523%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250523T200513Z&X-Amz-Expires=300&X-Amz-Signature=7194f3734d17a1c02f651df2caf2906713b4d22fd692d6b0d7a1291584551c95&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-23 20:05:57--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106867604/797840ed-70cb-47b8-a6fe-ecb4b3385c94?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250523%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250523T200513Z&X-Amz-Expires=300&X-Amz-Signature=7194f3734d17a1c02f651df2caf2906713b4d22fd692d6b0d7a1291584551c95&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3Dcloudflared-linux-amd64&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 37839075 (36M) [application/octet-stream]\n",
            "Saving to: ‘cloudflared-linux-amd64’\n",
            "\n",
            "cloudflared-linux-a 100%[===================>]  36.09M  56.5MB/s    in 0.6s    \n",
            "\n",
            "2025-05-23 20:05:58 (56.5 MB/s) - ‘cloudflared-linux-amd64’ saved [37839075/37839075]\n",
            "\n",
            "Tu aplicación está disponible en: https://disorders-else-happiness-reproduce.trycloudflare.com\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Finalización de ejecución del Dashboard**"
      ],
      "metadata": {
        "id": "uT6Mjt2Ke6At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "res = input(\"Digite (1) para finalizar la ejecución del Dashboard: \")\n",
        "\n",
        "if res.upper() == \"1\":\n",
        "    os.system(\"pkill streamlit\")  # Termina el proceso de Streamlit\n",
        "    print(\"El proceso de Streamlit ha sido finalizado.\")\n"
      ],
      "metadata": {
        "id": "BTtojSodRulL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc7f1f85-2037-43e9-906a-2fef16b97adf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Digite (1) para finalizar la ejecución del Dashboard: 1\n",
            "El proceso de Streamlit ha sido finalizado.\n"
          ]
        }
      ]
    }
  ]
}