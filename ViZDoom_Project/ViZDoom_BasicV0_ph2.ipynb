{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12405055,"sourceType":"datasetVersion","datasetId":7823007}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/juacastanori/doom-torch?scriptVersionId=249331554\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# ───── INSTALACIÓN ─────\n!pip install -q vizdoom==1.2.4 gymnasium==0.28.1 pyvirtualdisplay \\\n               imageio imageio-ffmpeg opencv-python-headless \\\n               torch torchvision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T03:52:09.368854Z","iopub.execute_input":"2025-07-08T03:52:09.369501Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── IMPORTS ─────\nfrom pyvirtualdisplay import Display\nDisplay(visible=0, size=(640,480)).start()\n\nimport gymnasium as gnm, gym as ogym\nimport numpy as np, random, cv2, imageio\nimport torch, torch.nn as nn, torch.optim as optim\nfrom collections import deque, namedtuple\nfrom vizdoom import gymnasium_wrapper\nfrom IPython.display import Video, display\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T03:52:21.535247Z","iopub.execute_input":"2025-07-08T03:52:21.536126Z","iopub.status.idle":"2025-07-08T03:52:21.617354Z","shell.execute_reply.started":"2025-07-08T03:52:21.536092Z","shell.execute_reply":"2025-07-08T03:52:21.616711Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── ENV WRAPPER ─────\nclass RGBOnly(ogym.Wrapper):\n    def __init__(self, env):\n        super().__init__(env)\n        self.action_space = ogym.spaces.Discrete(env.action_space.n)\n        self.observation_space = ogym.spaces.Box(0,255,(240,320,3),np.uint8)\n    def reset(self, **kwargs):\n        obs,_ = self.env.reset(**kwargs)\n        return obs[\"screen\"]\n    def step(self, action):\n        obs, r, term, trunc, info = self.env.step(action)\n        return obs[\"screen\"], r, term or trunc, info\n\n# ───── MODELO ─────\nclass DuelingDQN(nn.Module):\n    def __init__(self, in_channels=4, num_actions=6):\n        super().__init__()\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels,32,8,4), nn.ReLU(),\n            nn.Conv2d(32,64,4,2), nn.ReLU(),\n            nn.Conv2d(64,64,3,1), nn.ReLU()\n        )\n        convw = (((84-8)//4+1 -4)//2+1 -3)//1+1\n        linear_size = convw*convw*64\n        self.fc_value = nn.Sequential(nn.Linear(linear_size,512), nn.ReLU(), nn.Linear(512,1))\n        self.fc_adv   = nn.Sequential(nn.Linear(linear_size,512), nn.ReLU(), nn.Linear(512,num_actions))\n    def forward(self, x):\n        x = x / 255.0\n        o = self.conv(x).view(x.size(0), -1)\n        V = self.fc_value(o)\n        A = self.fc_adv(o)\n        return V + (A - A.mean(dim=1,keepdim=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T03:52:32.192081Z","iopub.execute_input":"2025-07-08T03:52:32.192351Z","iopub.status.idle":"2025-07-08T03:52:32.201624Z","shell.execute_reply.started":"2025-07-08T03:52:32.192329Z","shell.execute_reply":"2025-07-08T03:52:32.200944Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── BUFFER ─────\nTransition = namedtuple('Transition', ('s','a','r','s2','d'))\nclass ReplayBuffer:\n    def __init__(self, capacity=100000):\n        self.buf = deque(maxlen=capacity)\n    def push(self, *args): self.buf.append(Transition(*args))\n    def sample(self, bs): return random.sample(self.buf, bs)\n    def __len__(self): return len(self.buf)\n\n# ───── PREPROCESAMIENTO ─────\ndef preprocess(frame):\n    gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n    resized = cv2.resize(gray, (84,84))\n    return resized\n\ndef stack_frames(st, new_frame, is_new):\n    f = preprocess(new_frame)\n    if is_new:\n        st = np.stack([f]*4, axis=0)\n    else:\n        st = np.concatenate([st[1:], [f]], axis=0)\n    return st","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:00:36.888272Z","iopub.execute_input":"2025-07-08T04:00:36.888928Z","iopub.status.idle":"2025-07-08T04:00:36.896345Z","shell.execute_reply.started":"2025-07-08T04:00:36.888885Z","shell.execute_reply":"2025-07-08T04:00:36.895369Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── CONFIG ENTORNO Y MODELO ─────\nenv = RGBOnly(gnm.make(\"VizdoomBasic-v0\", render_mode=\"rgb_array\"))\nNUM_ACTIONS = env.action_space.n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\npolicy_net = DuelingDQN(4, NUM_ACTIONS).to(device)\ntarget_net = DuelingDQN(4, NUM_ACTIONS).to(device)\noptimizer = optim.Adam(policy_net.parameters(), lr=1e-4)\ntarget_net.load_state_dict(policy_net.state_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:00:39.999839Z","iopub.execute_input":"2025-07-08T04:00:40.000119Z","iopub.status.idle":"2025-07-08T04:00:40.410659Z","shell.execute_reply.started":"2025-07-08T04:00:40.000098Z","shell.execute_reply":"2025-07-08T04:00:40.409743Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── CARGAR MODELO SI EXISTE ─────\ntry:\n    model_path = \"/kaggle/input/doom-dqn-model/dueling_dqn_vizdoom.pth\"\n    policy_net.load_state_dict(torch.load(model_path))\n    target_net.load_state_dict(torch.load(model_path))\n    print(\"✅ Modelo cargado correctamente\")\nexcept:\n    print(\"⚠️ No se encontró modelo previo, se iniciará desde cero\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:00:42.208238Z","iopub.execute_input":"2025-07-08T04:00:42.208687Z","iopub.status.idle":"2025-07-08T04:00:42.272898Z","shell.execute_reply.started":"2025-07-08T04:00:42.208656Z","shell.execute_reply":"2025-07-08T04:00:42.272192Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── HYPERPARÁMETROS ─────\nbatch_size = 32\ngamma = 0.99\neps_start, eps_end, eps_decay = 1.0, 0.1, 10000\ntarget_update = 1000\nsteps_done = 0\nbuffer = ReplayBuffer()\nepisode_rewards = []\n\n# ───── SELECCIÓN DE ACCIÓN ─────\ndef select_action(state):\n    global steps_done\n    eps = eps_end + (eps_start - eps_end) * np.exp(-1. * steps_done / eps_decay)\n    steps_done += 1\n    if random.random() < eps:\n        return random.randrange(NUM_ACTIONS)\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        return policy_net(s).argmax().item()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:00:51.12738Z","iopub.execute_input":"2025-07-08T04:00:51.12771Z","iopub.status.idle":"2025-07-08T04:00:51.155593Z","shell.execute_reply.started":"2025-07-08T04:00:51.127687Z","shell.execute_reply":"2025-07-08T04:00:51.154845Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── ENTRENAMIENTO ─────\nnum_episodes = 1000  # puedes ajustar esto\nfor epi in range(num_episodes):\n    frame = env.reset()\n    state = stack_frames(None, frame, True)\n    total_r = 0\n    done = False\n    while not done:\n        a = select_action(state)\n        frame2, r, done, _ = env.step(a)\n        total_r += r\n        next_state = stack_frames(state, frame2, False)\n        buffer.push(state, a, r, next_state, done)\n        state = next_state\n\n        if len(buffer) >= batch_size:\n            batch = buffer.sample(batch_size)\n            bs = Transition(*zip(*batch))\n            s = torch.tensor(np.stack(bs.s), dtype=torch.float32, device=device)\n            a = torch.tensor(bs.a, dtype=torch.int64, device=device).unsqueeze(1)\n            r = torch.tensor(bs.r, dtype=torch.float32, device=device).unsqueeze(1)\n            s2 = torch.tensor(np.stack(bs.s2), dtype=torch.float32, device=device)\n            d = torch.tensor(bs.d, dtype=torch.float32, device=device).unsqueeze(1)\n\n            q_eval = policy_net(s).gather(1, a)\n            with torch.no_grad():\n                q_next = target_net(s2).max(1)[0].unsqueeze(1)\n                q_target = r + gamma * q_next * (1 - d)\n\n            loss = nn.MSELoss()(q_eval, q_target)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n        if steps_done % target_update == 0:\n            target_net.load_state_dict(policy_net.state_dict())\n\n    episode_rewards.append(total_r)\n    print(f\"🎯 Episodio {epi+1}/{num_episodes}, Recompensa: {total_r:.2f}\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:01:00.85694Z","iopub.execute_input":"2025-07-08T04:01:00.85725Z","iopub.status.idle":"2025-07-08T04:06:49.982432Z","shell.execute_reply.started":"2025-07-08T04:01:00.857227Z","shell.execute_reply":"2025-07-08T04:06:49.981461Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── GRAFICAR RECOMPENSAS ─────\nplt.figure(figsize=(10,4))\nplt.plot(episode_rewards, label='Recompensa por episodio')\nplt.xlabel('Episodio')\nplt.ylabel('Recompensa')\nplt.title('Curva de aprendizaje - Continuación')\nplt.grid(True)\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:06:52.84169Z","iopub.execute_input":"2025-07-08T04:06:52.842213Z","iopub.status.idle":"2025-07-08T04:06:53.075366Z","shell.execute_reply.started":"2025-07-08T04:06:52.842187Z","shell.execute_reply":"2025-07-08T04:06:53.074692Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:06:58.015692Z","iopub.execute_input":"2025-07-08T04:06:58.01596Z","iopub.status.idle":"2025-07-08T04:06:58.545011Z","shell.execute_reply.started":"2025-07-08T04:06:58.015942Z","shell.execute_reply":"2025-07-08T04:06:58.544015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:07:07.172725Z","iopub.execute_input":"2025-07-08T04:07:07.173561Z","iopub.status.idle":"2025-07-08T04:07:07.6757Z","shell.execute_reply.started":"2025-07-08T04:07:07.173514Z","shell.execute_reply":"2025-07-08T04:07:07.674696Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:07:16.885046Z","iopub.execute_input":"2025-07-08T04:07:16.885931Z","iopub.status.idle":"2025-07-08T04:07:17.372071Z","shell.execute_reply.started":"2025-07-08T04:07:16.885899Z","shell.execute_reply":"2025-07-08T04:07:17.370805Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:07:25.933084Z","iopub.execute_input":"2025-07-08T04:07:25.933879Z","iopub.status.idle":"2025-07-08T04:07:26.319093Z","shell.execute_reply.started":"2025-07-08T04:07:25.933849Z","shell.execute_reply":"2025-07-08T04:07:26.317912Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:07:39.725559Z","iopub.execute_input":"2025-07-08T04:07:39.726364Z","iopub.status.idle":"2025-07-08T04:07:40.0035Z","shell.execute_reply.started":"2025-07-08T04:07:39.72633Z","shell.execute_reply":"2025-07-08T04:07:40.002321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:07:46.701291Z","iopub.execute_input":"2025-07-08T04:07:46.702035Z","iopub.status.idle":"2025-07-08T04:07:47.174713Z","shell.execute_reply.started":"2025-07-08T04:07:46.702007Z","shell.execute_reply":"2025-07-08T04:07:47.17368Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:07:51.149439Z","iopub.execute_input":"2025-07-08T04:07:51.149738Z","iopub.status.idle":"2025-07-08T04:07:51.519529Z","shell.execute_reply.started":"2025-07-08T04:07:51.149714Z","shell.execute_reply":"2025-07-08T04:07:51.518176Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:07:56.686229Z","iopub.execute_input":"2025-07-08T04:07:56.686543Z","iopub.status.idle":"2025-07-08T04:07:57.135719Z","shell.execute_reply.started":"2025-07-08T04:07:56.686512Z","shell.execute_reply":"2025-07-08T04:07:57.134739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:03.942119Z","iopub.execute_input":"2025-07-08T04:08:03.942425Z","iopub.status.idle":"2025-07-08T04:08:04.214717Z","shell.execute_reply.started":"2025-07-08T04:08:03.942398Z","shell.execute_reply":"2025-07-08T04:08:04.213646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:08.150294Z","iopub.execute_input":"2025-07-08T04:08:08.150651Z","iopub.status.idle":"2025-07-08T04:08:08.47389Z","shell.execute_reply.started":"2025-07-08T04:08:08.15062Z","shell.execute_reply":"2025-07-08T04:08:08.472739Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:12.979096Z","iopub.execute_input":"2025-07-08T04:08:12.979432Z","iopub.status.idle":"2025-07-08T04:08:13.24986Z","shell.execute_reply.started":"2025-07-08T04:08:12.979403Z","shell.execute_reply":"2025-07-08T04:08:13.248631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:17.157532Z","iopub.execute_input":"2025-07-08T04:08:17.157808Z","iopub.status.idle":"2025-07-08T04:08:17.666272Z","shell.execute_reply.started":"2025-07-08T04:08:17.157784Z","shell.execute_reply":"2025-07-08T04:08:17.665211Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:22.565496Z","iopub.execute_input":"2025-07-08T04:08:22.565769Z","iopub.status.idle":"2025-07-08T04:08:22.831235Z","shell.execute_reply.started":"2025-07-08T04:08:22.565748Z","shell.execute_reply":"2025-07-08T04:08:22.830064Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:26.751236Z","iopub.execute_input":"2025-07-08T04:08:26.751592Z","iopub.status.idle":"2025-07-08T04:08:27.137315Z","shell.execute_reply.started":"2025-07-08T04:08:26.751562Z","shell.execute_reply":"2025-07-08T04:08:27.136242Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:46.253905Z","iopub.execute_input":"2025-07-08T04:08:46.254525Z","iopub.status.idle":"2025-07-08T04:08:46.752974Z","shell.execute_reply.started":"2025-07-08T04:08:46.254494Z","shell.execute_reply":"2025-07-08T04:08:46.751972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:51.494218Z","iopub.execute_input":"2025-07-08T04:08:51.495023Z","iopub.status.idle":"2025-07-08T04:08:51.960315Z","shell.execute_reply.started":"2025-07-08T04:08:51.494992Z","shell.execute_reply":"2025-07-08T04:08:51.959166Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:08:56.798014Z","iopub.execute_input":"2025-07-08T04:08:56.798695Z","iopub.status.idle":"2025-07-08T04:08:57.1608Z","shell.execute_reply.started":"2025-07-08T04:08:56.798662Z","shell.execute_reply":"2025-07-08T04:08:57.159613Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:02.534774Z","iopub.execute_input":"2025-07-08T04:09:02.535068Z","iopub.status.idle":"2025-07-08T04:09:02.907715Z","shell.execute_reply.started":"2025-07-08T04:09:02.535041Z","shell.execute_reply":"2025-07-08T04:09:02.906618Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:06.838109Z","iopub.execute_input":"2025-07-08T04:09:06.838408Z","iopub.status.idle":"2025-07-08T04:09:07.211611Z","shell.execute_reply.started":"2025-07-08T04:09:06.838382Z","shell.execute_reply":"2025-07-08T04:09:07.210336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:11.519744Z","iopub.execute_input":"2025-07-08T04:09:11.520571Z","iopub.status.idle":"2025-07-08T04:09:11.907892Z","shell.execute_reply.started":"2025-07-08T04:09:11.520537Z","shell.execute_reply":"2025-07-08T04:09:11.906924Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:16.81496Z","iopub.execute_input":"2025-07-08T04:09:16.815863Z","iopub.status.idle":"2025-07-08T04:09:17.283145Z","shell.execute_reply.started":"2025-07-08T04:09:16.815828Z","shell.execute_reply":"2025-07-08T04:09:17.282014Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:21.680331Z","iopub.execute_input":"2025-07-08T04:09:21.680661Z","iopub.status.idle":"2025-07-08T04:09:22.076159Z","shell.execute_reply.started":"2025-07-08T04:09:21.680633Z","shell.execute_reply":"2025-07-08T04:09:22.075018Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:26.305682Z","iopub.execute_input":"2025-07-08T04:09:26.306561Z","iopub.status.idle":"2025-07-08T04:09:26.651441Z","shell.execute_reply.started":"2025-07-08T04:09:26.306522Z","shell.execute_reply":"2025-07-08T04:09:26.650262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:41.111594Z","iopub.execute_input":"2025-07-08T04:09:41.111925Z","iopub.status.idle":"2025-07-08T04:09:41.588711Z","shell.execute_reply.started":"2025-07-08T04:09:41.111898Z","shell.execute_reply":"2025-07-08T04:09:41.587781Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:09:46.559606Z","iopub.execute_input":"2025-07-08T04:09:46.560382Z","iopub.status.idle":"2025-07-08T04:09:46.958462Z","shell.execute_reply.started":"2025-07-08T04:09:46.560355Z","shell.execute_reply":"2025-07-08T04:09:46.957545Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── VIDEO FINAL ─────\nwriter = imageio.get_writer(\"doom_dueling_test.mp4\", fps=35)\nframe = env.reset()\nstate = stack_frames(None, frame, True)\ndone = False\nepisode_reward = 0.0\n\nwhile not done:\n    with torch.no_grad():\n        s = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n        a = policy_net(s).argmax().item()\n    frame2, r, done, _ = env.step(a)\n    episode_reward += r\n    state = stack_frames(state, frame2, False)\n    vis = frame2.copy()\n    cv2.putText(vis, str(a), (5,30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)\n    writer.append_data(vis)\nwriter.close()\ndisplay(Video(\"doom_dueling_test.mp4\", embed=True, width=640))\nprint(f\"🎯 Recompensa total del video: {episode_reward:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:10:03.447346Z","iopub.execute_input":"2025-07-08T04:10:03.448202Z","iopub.status.idle":"2025-07-08T04:10:03.996522Z","shell.execute_reply.started":"2025-07-08T04:10:03.448169Z","shell.execute_reply":"2025-07-08T04:10:03.995536Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ───── GUARDAR MODELO ─────\ntorch.save(policy_net.state_dict(), \"dueling_model2.pth\")\nprint(\"💾 Modelo guardado como dueling_model2.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-08T04:13:28.296294Z","iopub.execute_input":"2025-07-08T04:13:28.297149Z","iopub.status.idle":"2025-07-08T04:13:28.34542Z","shell.execute_reply.started":"2025-07-08T04:13:28.297115Z","shell.execute_reply":"2025-07-08T04:13:28.344355Z"}},"outputs":[],"execution_count":null}]}